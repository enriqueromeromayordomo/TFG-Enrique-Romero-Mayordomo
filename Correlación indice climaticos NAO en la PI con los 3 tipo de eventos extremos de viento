import pandas as pd
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import pearsonr
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import os
from matplotlib.colors import Normalize

RUTA_WIND = "F:/windgust/data_daily_gust_1950_2012.nc"
RUTA_NAO = "F:/variables climaticas/NAO/NAO_1950_2012.csv"
RUTA_SALIDA = "F:/variables climaticas/NAO/correlacion_NAO_wind_gust.csv"
RUTA_GRAFICOS = "F:/variables climaticas/NAO/graficos_correlacion/"
MAX_SHIFT = 120  

os.makedirs(RUTA_GRAFICOS, exist_ok=True)

def cargar_nao(ruta):
    """Carga y prepara los datos NAO"""
    df = pd.read_csv(ruta)
    df['fecha'] = pd.to_datetime(df[['year', 'month', 'day']])
    return df.set_index('fecha')['ao_index_cdas']

def procesar_nodo(lat, lon, nao_series, ds_wind, max_shift):
    """Procesa un nodo individual, considerando solo shifts positivos"""
    try:
        nodo_wind = ds_wind["var29"].sel(
            lat=lat, lon=lon, 
            method="nearest",
            tolerance=0.125
        )
        
        fechas_wind = pd.to_datetime(
            [f"{int(t)}"[:8] for t in nodo_wind.time.values], 
            format='%Y%m%d'
        )
        
        wind_series = pd.Series(
            nodo_wind.values,
            index=fechas_wind
        ).dropna()
        
        common_dates = wind_series.index.intersection(nao_series.index)
        wind_aligned = wind_series[common_dates]
        nao_aligned = nao_series[common_dates]
        
        best_corr = 0 
        best_shift = 0
        best_abs_corr = 0  
        
        correlaciones = []
        shifts = range(0, max_shift + 1)
        
        for shift in shifts:
            shifted_nao = nao_aligned.shift(-shift).dropna()
            wind_valid = wind_aligned[shifted_nao.index]
            
            if len(wind_valid) > 10:
                corr = pearsonr(shifted_nao, wind_valid)[0]
                correlaciones.append(corr)
                
                if abs(corr) > abs(best_abs_corr):
                    best_abs_corr = corr
                    best_corr = corr
                    best_shift = shift
            else:
                correlaciones.append(np.nan)
        
        return {
            'lat': lat,
            'lon': lon,
            'shift_optimo': best_shift,
            'correlacion_max': best_corr,
            'correlacion_abs_max': best_abs_corr,
            'puntos_validos': len(common_dates),
            'correlaciones_shifts': correlaciones,
            'shifts': list(shifts)
        }
        
    except Exception as e:
        print(f"Error procesando nodo ({lat}, {lon}): {str(e)}")
        return {
            'lat': lat,
            'lon': lon,
            'shift_optimo': np.nan,
            'correlacion_max': np.nan,
            'correlacion_abs_max': np.nan,
            'puntos_validos': 0,
            'correlaciones_shifts': [],
            'shifts': []
        }

def graficar_correlacion_shifts(df_resultados, ciudades, ruta_graficos):
    """Grafica correlación vs shift para ciudades específicas"""
    for ciudad, coords in ciudades.items():
      
        df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
        
        if df_valido.empty:
            print(f"No hay datos válidos para graficar cerca de {ciudad}")
            continue
            
        df_valido['distancia'] = np.sqrt(
            (df_valido['lat']-coords['lat'])**2 + 
            (df_valido['lon']-coords['lon'])**2
        )
        
        nodo_cercano = df_valido.nsmallest(1, 'distancia').iloc[0]
        
        if not isinstance(nodo_cercano.get('correlaciones_shifts', ''), str):
            print(f"No hay datos de shifts para {ciudad}")
            continue
            
        try:
            import ast
            correlaciones = ast.literal_eval(nodo_cercano['correlaciones_shifts'])
            shifts = ast.literal_eval(nodo_cercano['shifts'])
            
            plt.figure(figsize=(10, 6))
            plt.plot(shifts, correlaciones, 'b-', label='Correlación')
            plt.axhline(0, color='k', linestyle='--', linewidth=0.5)
            plt.axvline(0, color='k', linestyle='--', linewidth=0.5)
            
            plt.axvline(nodo_cercano['shift_optimo'], color='r', linestyle='--', 
                       label=f'Shift óptimo: {nodo_cercano["shift_optimo"]} días')
            
            plt.xlabel('Shift (días)')
            plt.ylabel('Correlación')
            plt.title(f'Correlación NAO-Wind Gust vs Shift\n{ciudad} (Lat: {nodo_cercano["lat"]:.2f}, Lon: {nodo_cercano["lon"]:.2f})')
            plt.grid(True, alpha=0.3)
            plt.legend()
            
            nombre_archivo = f"correlacion_shift_{ciudad.lower()}.png"
            ruta_completa = os.path.join(ruta_graficos, nombre_archivo)
            plt.savefig(ruta_completa, dpi=300, bbox_inches='tight')
            print(f"Gráfico de {ciudad} guardado en: {ruta_completa}")
            plt.close()
            
        except Exception as e:
            print(f"Error al graficar {ciudad}: {str(e)}")

print("Cargando datos...")
nao_series = cargar_nao(RUTA_NAO)
ds_wind = xr.open_dataset(RUTA_WIND, decode_times=False)

lat_values = np.arange(
    round(float(ds_wind.lat.min()), 2),
    round(float(ds_wind.lat.max()), 2) + 0.25,
    0.25
)
lon_values = np.arange(
    round(float(ds_wind.lon.min()), 2),
    round(float(ds_wind.lon.max()), 2) + 0.25,
    0.25
)

print("\nIniciando procesamiento de todos los nodos...")
resultados = []
total_nodos = len(lat_values) * len(lon_values)
nodos_procesados = 0

for lat in lat_values:
    for lon in lon_values:
        nodos_procesados += 1
        print(f"\rProgreso: {nodos_procesados}/{total_nodos} nodos | Lat: {lat:.2f} Lon: {lon:.2f}", end="")
        resultados.append(procesar_nodo(lat, lon, nao_series, ds_wind, MAX_SHIFT))

df_resultados = pd.DataFrame(resultados)
df_resultados.to_csv(RUTA_SALIDA, index=False)
print(f"\n\nResultados guardados en: {RUTA_SALIDA}")

ciudades = {
    'Madrid': {'lat': 40.5, 'lon': -3.5},  
    'Barcelona': {'lat': 41.25, 'lon': 2.0},
    'Sevilla': {'lat': 37.25, 'lon': -5.75},
    'Cadiz': {'lat': 36.5, 'lon': -6.25},
    'Mallorca': {'lat': 39.5, 'lon': 3.0}
}

graficar_correlacion_shifts(df_resultados, ciudades, RUTA_GRAFICOS)

df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
df_valido['abs_corr'] = df_valido['correlacion_max'].abs()

if not df_valido.empty:
    print("\n=== Estadísticas de Correlaciones ===")
    print(f"Shift medio: {df_valido['shift_optimo'].mean():.1f} días")
    print(f"Shift máximo: {df_valido['shift_optimo'].max()} días")
    print(f"Shift mínimo: {df_valido['shift_optimo'].min()} días")
    print(f"Correlación absoluta máxima: {df_valido['abs_corr'].max():.3f}")
    print(f"Correlación absoluta mínima: {df_valido['abs_corr'].min():.3f}")
    print(f"Correlación absoluta media: {df_valido['abs_corr'].mean():.3f}")
    
    positivas = df_valido[df_valido['correlacion_max'] > 0]
    negativas = df_valido[df_valido['correlacion_max'] < 0]
    
    print("\nCorrelaciones positivas:")
    print(f"  Cantidad: {len(positivas)} ({len(positivas)/len(df_valido)*100:.1f}%)")
    if not positivas.empty:
        print(f"  Máxima: {positivas['correlacion_max'].max():.3f}")
        print(f"  Mínima: {positivas['correlacion_max'].min():.3f}")
    
    print("\nCorrelaciones negativas:")
    print(f"  Cantidad: {len(negativas)} ({len(negativas)/len(df_valido)*100:.1f}%)")
    if not negativas.empty:
        print(f"  Máxima: {negativas['correlacion_max'].max():.3f}")
        print(f"  Mínima: {negativas['correlacion_max'].min():.3f}")
else:
    print("\nNo se encontraron correlaciones significativas.")

if not df_valido.empty:
    print("\nGenerando mapa de correlaciones...")
    plt.figure(figsize=(14, 10))
    ax = plt.axes(projection=ccrs.PlateCarree())
    
    ax.add_feature(cfeature.LAND, facecolor='lightgray')
    ax.add_feature(cfeature.OCEAN, facecolor='lightblue')
    ax.add_feature(cfeature.COASTLINE)
    ax.add_feature(cfeature.BORDERS, linestyle=':')
    
    corr_max = df_valido['correlacion_max'].abs().max()
    sc = ax.scatter(
        df_valido['lon'], 
        df_valido['lat'], 
        c=df_valido['correlacion_max'], 
        cmap='coolwarm', 
        vmin=-corr_max, 
        vmax=corr_max,
        s=30,
        transform=ccrs.PlateCarree()
    )
    
    cbar = plt.colorbar(sc, shrink=0.7)
    cbar.set_label('Correlación NAO-Wind Gust')
    
    ciudades_plot = {
        'Madrid': (40.5, -3.5),
        'Barcelona': (41.25, 2.0),
        'Sevilla': (37.25, -5.75),
        'Cádiz': (36.5, -6.25),
        'Mallorca': (39.5, 3.0)
    }
    
    for ciudad, (lat, lon) in ciudades_plot.items():
        ax.plot(lon, lat, 'ko', markersize=5, transform=ccrs.PlateCarree())
        ax.text(lon + 0.1, lat + 0.1, ciudad, 
                transform=ccrs.PlateCarree(), fontsize=10)
    
    plt.title("Correlaciones NAO-Wind Gust (1950-2012)\n(Shifts positivos de 0 a 120 días)")
    plt.tight_layout()
    
    ruta_mapa = os.path.join(os.path.dirname(RUTA_SALIDA), "mapa_correlaciones_NAO_wind_gust.png")
    plt.savefig(ruta_mapa, dpi=300, bbox_inches='tight')
    print(f"Mapa de correlaciones guardado en: {ruta_mapa}")
    plt.show()
else:
    print("No hay datos válidos para graficar.")









import pandas as pd
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import pearsonr
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import os
import glob
import warnings
import sys
from matplotlib.colors import Normalize

RUTA_MODULO = "F:/moduloydireccion/[0-9][0-9][0-9][0-9]modulo.nc"
RUTA_NAO = "F:/variables climaticas/NAO/NAO_1950_2025.csv"
RUTA_SALIDA = "F:/variables climaticas/NAO/correlacion_shift_NAO_extremo_1950_2024.csv"
RUTA_GRAFICOS = "F:/variables climaticas/NAO/graficos_correlacion/"
MAX_SHIFT = 120  
PERCENTIL = 99 
REGION_IBERICA = {'lat_min': 34, 'lat_max': 45, 'lon_min': -11, 'lon_max': 6}

os.makedirs(RUTA_GRAFICOS, exist_ok=True)

def mostrar_progreso(iterable, desc=None, total=None):
    """Muestra una barra de progreso simple"""
    if total is None and hasattr(iterable, '__len__'):
        total = len(iterable)
    
    if desc:
        print(desc)
    
    for i, item in enumerate(iterable):
        yield item
        if total:
            porcentaje = (i + 1) / total * 100
            sys.stdout.write(f"\rProgreso: {i+1}/{total} ({porcentaje:.1f}%)")
            sys.stdout.flush()
    
    if total:
        print() 

def cargar_nao(ruta):
    """Carga y prepara los datos NAO"""
    print("\nCargando datos NAO...")
    df = pd.read_csv(ruta)
    df['fecha'] = pd.to_datetime(df[['year', 'month', 'day']])
    return df.set_index('fecha')['ao_index_cdas']

def cargar_datos_viento(ruta_patron):
    """Carga archivos de viento de forma eficiente en memoria"""
    archivos = sorted(glob.glob(ruta_patron))
    
    if not archivos:
        raise ValueError("No se encontraron archivos que coincidan con el patrón")
    
    print("\nCargando datos de viento (1950-2024) por bloques...")
    
    template = None
    for archivo in archivos[:5]: 
        try:
            with xr.open_dataset(archivo) as ds:
                time_var = next((v for v in ds.dims if v.lower() in ['time', 'valid_time', 'ftime']), None)
                wind_var = next((v for v in ds.data_vars if 'wind' in v.lower()), None)
                
                if time_var and wind_var:
                    template = ds[wind_var].isel({time_var: 0})
                    break
        except Exception as e:
            continue
    
    if template is None:
        raise ValueError("No se pudo determinar la estructura de los datos")
    
    lat_slice = slice(REGION_IBERICA['lat_max'], REGION_IBERICA['lat_min'])
    lon_slice = slice(REGION_IBERICA['lon_min'], REGION_IBERICA['lon_max'])
    
    template = template.sel(latitude=lat_slice, longitude=lon_slice)
    
    datasets = []
    for archivo in mostrar_progreso(archivos, "Procesando archivos de viento"):
        try:
            year = int(os.path.basename(archivo)[:4])
            if 1950 <= year <= 2024:
                with xr.open_dataset(archivo) as ds:
                    time_var = next((v for v in ds.dims if v.lower() in ['time', 'valid_time', 'ftime']), None)
                    wind_var = next((v for v in ds.data_vars if 'wind' in v.lower()), None)
                    
                    if time_var and wind_var:
                        if time_var != 'time':
                            ds = ds.rename({time_var: 'time'})
                        
                        ds = ds[[wind_var]].sel(latitude=lat_slice, longitude=lon_slice)
                        
                        
                        ds[wind_var] = ds[wind_var].astype('float32')
                        
                        datasets.append(ds.load())  
        except Exception as e:
            print(f"\nError procesando {os.path.basename(archivo)}: {str(e)}")
            continue
    
    if not datasets:
        raise ValueError("No se encontraron datos válidos después del procesamiento")
    
    print("\nConcatenando datos...")
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        combined = xr.concat(datasets, dim='time', combine_attrs='override', coords='minimal')
    
    return combined

def calcular_extremos_diarios(ds_viento):
    """Calcula el percentil 99 diario para cada nodo de forma eficiente"""
    print("\nCalculando extremos diarios...")
    
    wind_var = list(ds_viento.data_vars)[0] 
    
    print("Calculando máximo diario...")
    daily_max = ds_viento[wind_var].resample(time='1D').max()
    
    print("Calculando percentil 99...")
    percentil = daily_max.quantile(PERCENTIL/100, dim='time')
    
    print("Creando máscara de extremos...")
    extremos = xr.where(daily_max >= percentil, 1, 0)
    
    return extremos

def procesar_nodo(lat, lon, nao_series, extremos_daily, max_shift):
    """Procesa un nodo individual considerando correlaciones positivas y negativas"""
    try:
        nodo_data = extremos_daily.sel(
            latitude=lat,
            longitude=lon,
            method="nearest"
        )
        
        extremos_series = pd.Series(
            nodo_data.values,
            index=pd.to_datetime(nodo_data.time.values),
            dtype='int8' 
        ).dropna()
        
        common_idx = nao_series.index.intersection(extremos_series.index)
        if len(common_idx) < 365:
            raise ValueError("Datos insuficientes")
        
        nao_aligned = nao_series[common_idx]
        extremos_aligned = extremos_series[common_idx]
        
        best_corr = 0
        best_shift = 0
        best_abs_corr = 0 
        
        correlaciones = []
        shifts = range(0, max_shift + 1, 5)  
        
        for shift in shifts:
            shifted_nao = nao_aligned.shift(-shift).dropna()
            extremos_valid = extremos_aligned[shifted_nao.index]
            
            if len(extremos_valid) > 365:
                corr = pearsonr(shifted_nao, extremos_valid)[0]
                correlaciones.append(corr)
                
                if abs(corr) > abs(best_abs_corr):
                    best_abs_corr = corr
                    best_corr = corr
                    best_shift = shift
            else:
                correlaciones.append(np.nan)
        
        for shift in range(max(0, best_shift-4), min(max_shift, best_shift+5)):
            shifted_nao = nao_aligned.shift(-shift).dropna()
            extremos_valid = extremos_aligned[shifted_nao.index]
            
            if len(extremos_valid) > 365:
                corr = pearsonr(shifted_nao, extremos_valid)[0]
                if abs(corr) > abs(best_abs_corr):
                    best_abs_corr = corr
                    best_corr = corr
                    best_shift = shift
        
        return {
            'lat': float(lat),
            'lon': float(lon),
            'shift_optimo': int(best_shift),
            'correlacion_max': float(best_corr),
            'correlacion_abs_max': float(best_abs_corr),
            'puntos_validos': int(len(common_idx)),
            'correlaciones_shifts': correlaciones,
            'shifts': list(shifts)
        }
        
    except Exception as e:
        print(f"Error en nodo ({lat:.2f}, {lon:.2f}): {str(e)}")
        return {
            'lat': float(lat),
            'lon': float(lon),
            'shift_optimo': np.nan,
            'correlacion_max': np.nan,
            'correlacion_abs_max': np.nan,
            'puntos_validos': 0,
            'correlaciones_shifts': [],
            'shifts': []
        }

def graficar_correlacion_shifts(df_resultados, ciudades, ruta_graficos):
    """Grafica correlación vs shift para ciudades específicas"""
    for ciudad, coords in ciudades.items():
      
        df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
        
        if df_valido.empty:
            print(f"No hay datos válidos para graficar cerca de {ciudad}")
            continue
            
        df_valido['distancia'] = np.sqrt(
            (df_valido['lat']-coords['lat'])**2 + 
            (df_valido['lon']-coords['lon'])**2
        )
        
        nodo_cercano = df_valido.nsmallest(1, 'distancia').iloc[0]
        
        if not nodo_cercano.get('correlaciones_shifts'):
            print(f"No hay datos de shifts para {ciudad}")
            continue
            
        try:
            plt.figure(figsize=(10, 6))
            plt.plot(nodo_cercano['shifts'], nodo_cercano['correlaciones_shifts'], 'b-', label='Correlación')
            plt.axhline(0, color='k', linestyle='--', linewidth=0.5)
            plt.axvline(0, color='k', linestyle='--', linewidth=0.5)
            
            plt.axvline(nodo_cercano['shift_optimo'], color='r', linestyle='--', 
                       label=f'Shift óptimo: {nodo_cercano["shift_optimo"]} días')
            
            plt.xlabel('Shift (días)')
            plt.ylabel('Correlación')
            plt.title(f'Correlación NAO-Viento Extremo vs Shift\n{ciudad} (Lat: {nodo_cercano["lat"]:.2f}, Lon: {nodo_cercano["lon"]:.2f})')
            plt.grid(True, alpha=0.3)
            plt.legend()
            
            nombre_archivo = f"correlacion_shift_{ciudad.lower().replace(' ', '_')}.png"
            ruta_completa = os.path.join(ruta_graficos, nombre_archivo)
            plt.savefig(ruta_completa, dpi=300, bbox_inches='tight')
            print(f"Gráfico de {ciudad} guardado en: {ruta_completa}")
            plt.close()
            
        except Exception as e:
            print(f"Error al graficar {ciudad}: {str(e)}")

if __name__ == "__main__":
    print("Iniciando análisis de correlación NAO - Viento Extremo (1950-2024)")
    
    try:
        nao_series = cargar_nao(RUTA_NAO)
        
        ds_viento = cargar_datos_viento(RUTA_MODULO)
        
        extremos_daily = calcular_extremos_diarios(ds_viento)
        
        del ds_viento
        
        lat_values = np.linspace(
            float(extremos_daily.latitude.min()),
            float(extremos_daily.latitude.max()),
            num=int((float(extremos_daily.latitude.max()) - float(extremos_daily.latitude.min())) / 0.25) + 1
        )
        
        lon_values = np.linspace(
            float(extremos_daily.longitude.min()),
            float(extremos_daily.longitude.max()),
            num=int((float(extremos_daily.longitude.max()) - float(extremos_daily.longitude.min())) / 0.25) + 1
        )
        
        print("\nProcesando nodos...")
        resultados = []
        total_nodos = len(lat_values) * len(lon_values)
        procesados = 0
        
        for lat in lat_values:
            for lon in lon_values:
                resultados.append(procesar_nodo(lat, lon, nao_series, extremos_daily, MAX_SHIFT))
                procesados += 1
                porcentaje = procesados / total_nodos * 100
                sys.stdout.write(f"\rProgreso: {procesados}/{total_nodos} ({porcentaje:.1f}%)")
                sys.stdout.flush()
        
        print()  
        
        df_resultados = pd.DataFrame(resultados)
        df_resultados.to_csv(RUTA_SALIDA, index=False)
        print(f"\nResultados guardados en: {RUTA_SALIDA}")
        
        ciudades = {
            'Madrid': {'lat': 40.5, 'lon': -3.5},
            'Barcelona': {'lat': 41.25, 'lon': 2.0},
            'Sevilla': {'lat': 37.25, 'lon': -5.75},
            'Cadiz': {'lat': 36.5, 'lon': -6.25},
            'Mallorca': {'lat': 39.5, 'lon': 3.0}
        }
        
        graficar_correlacion_shifts(df_resultados, ciudades, RUTA_GRAFICOS)
        
        df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
        df_valido['abs_corr'] = df_valido['correlacion_max'].abs()
        
        if not df_valido.empty:
            print("\n=== Resultados ===")
            print(f"Nodos con datos válidos: {len(df_valido)}/{len(df_resultados)}")
            print(f"Shift medio: {df_valido['shift_optimo'].mean():.1f} días")
            print(f"Correlación absoluta máxima: {df_valido['abs_corr'].max():.3f}")
            print(f"Correlación absoluta media: {df_valido['abs_corr'].mean():.3f}")
            
        
            positivas = df_valido[df_valido['correlacion_max'] > 0]
            negativas = df_valido[df_valido['correlacion_max'] < 0]
            
            print("\nCorrelaciones positivas:")
            print(f"  Cantidad: {len(positivas)} ({len(positivas)/len(df_valido)*100:.1f}%)")
            if not positivas.empty:
                print(f"  Máxima: {positivas['correlacion_max'].max():.3f}")
                print(f"  Mínima: {positivas['correlacion_max'].min():.3f}")
            
            print("\nCorrelaciones negativas:")
            print(f"  Cantidad: {len(negativas)} ({len(negativas)/len(df_valido)*100:.1f}%)")
            if not negativas.empty:
                print(f"  Máxima: {negativas['correlacion_max'].max():.3f}")
                print(f"  Mínima: {negativas['correlacion_max'].min():.3f}")
            
            print("\nGenerando mapa de correlaciones...")
            plt.figure(figsize=(14, 10))
            ax = plt.axes(projection=ccrs.PlateCarree())
            
            ax.add_feature(cfeature.LAND, facecolor='lightgray')
            ax.add_feature(cfeature.OCEAN, facecolor='lightblue')
            ax.add_feature(cfeature.COASTLINE)
            ax.add_feature(cfeature.BORDERS, linestyle=':')
            ax.set_extent([-11, 6, 34, 45])
            
            corr_max = df_valido['abs_corr'].max()
            sc = ax.scatter(
                df_valido['lon'],
                df_valido['lat'],
                c=df_valido['correlacion_max'],
                cmap='coolwarm',
                vmin=-corr_max,
                vmax=corr_max,
                s=15,
                transform=ccrs.PlateCarree()
            )
            
            cbar = plt.colorbar(sc, label='Correlación NAO - Viento Extremo', extend='both')
            
            for ciudad, coords in ciudades.items():
                ax.plot(coords['lon'], coords['lat'], 'ko', markersize=5, transform=ccrs.PlateCarree())
                ax.text(coords['lon'] + 0.1, coords['lat'] + 0.1, ciudad, 
                        transform=ccrs.PlateCarree(), fontsize=10)
            
            plt.title(f"Correlaciones NAO-Viento Extremo (1950-2024)\n"
                     f"Percentil {PERCENTIL} - Shift máximo: {MAX_SHIFT} días")
            
            ruta_mapa = os.path.join(os.path.dirname(RUTA_SALIDA), "mapa_correlacion_completo.png")
            plt.savefig(ruta_mapa, dpi=300, bbox_inches='tight')
            print(f"Mapa guardado en: {ruta_mapa}")
            plt.close()
        else:
            print("\nNo se encontraron correlaciones significativas.")
        
        print("\nProceso completado exitosamente!")
    
    except Exception as e:
        print(f"\nError durante la ejecución: {str(e)}")
        raise












import pandas as pd
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import pearsonr
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import os
import glob
import warnings
import sys
from matplotlib.colors import Normalize

RUTA_MODULO = "F:/moduloydireccion/[0-9][0-9][0-9][0-9]modulo.nc"
RUTA_NAO = "F:/variables climaticas/NAO/NAO_1950_2025.csv"
RUTA_SALIDA = "F:/variables climaticas/NAO/correlacion_shift_NAO_sequia_1950_2024.csv"
RUTA_GRAFICOS = "F:/variables climaticas/NAO/graficos_correlacion_sequia/"
MAX_SHIFT = 120  
PERCENTIL = 20   
REGION_IBERICA = {'lat_min': 34, 'lat_max': 45, 'lon_min': -11, 'lon_max': 6}

os.makedirs(RUTA_GRAFICOS, exist_ok=True)

def mostrar_progreso(iterable, desc=None, total=None):
    """Muestra una barra de progreso simple"""
    if total is None and hasattr(iterable, '__len__'):
        total = len(iterable)
    
    if desc:
        print(desc)
    
    for i, item in enumerate(iterable):
        yield item
        if total:
            porcentaje = (i + 1) / total * 100
            sys.stdout.write(f"\rProgreso: {i+1}/{total} ({porcentaje:.1f}%)")
            sys.stdout.flush()
    
    if total:
        print()

def cargar_nao(ruta):
    """Carga y prepara los datos NAO"""
    print("\nCargando datos NAO...")
    df = pd.read_csv(ruta)
    df['fecha'] = pd.to_datetime(df[['year', 'month', 'day']])
    return df.set_index('fecha')['ao_index_cdas']

def cargar_datos_viento(ruta_patron):
    """Carga archivos de viento de forma eficiente en memoria"""
    archivos = sorted(glob.glob(ruta_patron))
    
    if not archivos:
        raise ValueError("No se encontraron archivos que coincidan con el patrón")
    
    print("\nCargando datos de viento (1950-2024) por bloques...")
    
    template = None
    for archivo in archivos[:5]: 
        try:
            with xr.open_dataset(archivo) as ds:
                time_var = next((v for v in ds.dims if v.lower() in ['time', 'valid_time', 'ftime']), None)
                wind_var = next((v for v in ds.data_vars if 'wind' in v.lower()), None)
                
                if time_var and wind_var:
                    template = ds[wind_var].isel({time_var: 0})
                    break
        except Exception as e:
            continue
    
    if template is None:
        raise ValueError("No se pudo determinar la estructura de los datos")
    
    lat_slice = slice(REGION_IBERICA['lat_max'], REGION_IBERICA['lat_min'])
    lon_slice = slice(REGION_IBERICA['lon_min'], REGION_IBERICA['lon_max'])
    
    template = template.sel(latitude=lat_slice, longitude=lon_slice)
    
    datasets = []
    for archivo in mostrar_progreso(archivos, "Procesando archivos de viento"):
        try:
            year = int(os.path.basename(archivo)[:4])
            if 1950 <= year <= 2024:
                with xr.open_dataset(archivo) as ds:
                    time_var = next((v for v in ds.dims if v.lower() in ['time', 'valid_time', 'ftime']), None)
                    wind_var = next((v for v in ds.data_vars if 'wind' in v.lower()), None)
                    
                    if time_var and wind_var:
                        if time_var != 'time':
                            ds = ds.rename({time_var: 'time'})
                        
                        ds = ds[[wind_var]].sel(latitude=lat_slice, longitude=lon_slice)
                        
                      
                        ds[wind_var] = ds[wind_var].astype('float32')
                        
                        datasets.append(ds.load())  
        except Exception as e:
            print(f"\nError procesando {os.path.basename(archivo)}: {str(e)}")
            continue
    
    if not datasets:
        raise ValueError("No se encontraron datos válidos después del procesamiento")
    
    print("\nConcatenando datos...")
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        combined = xr.concat(datasets, dim='time', combine_attrs='override', coords='minimal')
    
    return combined

def calcular_sequias(ds_viento):
    """Identifica días de sequía según percentil 20 (valores bajos de viento)"""
    print("\nCalculando días de sequía...")
    
    wind_var = list(ds_viento.data_vars)[0]  
    
    print("Calculando mínimo diario...")
    daily_min = ds_viento[wind_var].resample(time='1D').min()
    
    print("Calculando percentil 20...")
    percentil = daily_min.quantile(PERCENTIL/100, dim='time')
    
    print("Creando máscara de sequía...")
    sequias = xr.where(daily_min <= percentil, 1, 0)
    
    return sequias

def procesar_nodo(lat, lon, nao_series, sequias_daily, max_shift):
    """Procesa un nodo individual considerando correlaciones positivas y negativas"""
    try:
        nodo_data = sequias_daily.sel(
            latitude=lat,
            longitude=lon,
            method="nearest"
        )
        
        sequia_series = pd.Series(
            nodo_data.values,
            index=pd.to_datetime(nodo_data.time.values),
            dtype='int8'  
        ).dropna()
        
        common_idx = nao_series.index.intersection(sequia_series.index)
        if len(common_idx) < 365:
            raise ValueError("Datos insuficientes")
        
        nao_aligned = nao_series[common_idx]
        sequia_aligned = sequia_series[common_idx]
        
        best_corr = 0
        best_shift = 0
        best_abs_corr = 0  
        
        correlaciones = []
        shifts = range(0, max_shift + 1, 5)  
        
        for shift in shifts:
            shifted_nao = nao_aligned.shift(-shift).dropna()
            sequia_valid = sequia_aligned[shifted_nao.index]
            
            if len(sequia_valid) > 365:
                corr = pearsonr(shifted_nao, sequia_valid)[0]
                correlaciones.append(corr)
                
                if abs(corr) > abs(best_abs_corr):
                    best_abs_corr = corr
                    best_corr = corr
                    best_shift = shift
            else:
                correlaciones.append(np.nan)
        
        for shift in range(max(0, best_shift-4), min(max_shift, best_shift+5)):
            shifted_nao = nao_aligned.shift(-shift).dropna()
            sequia_valid = sequia_aligned[shifted_nao.index]
            
            if len(sequia_valid) > 365:
                corr = pearsonr(shifted_nao, sequia_valid)[0]
                if abs(corr) > abs(best_abs_corr):
                    best_abs_corr = corr
                    best_corr = corr
                    best_shift = shift
        
        return {
            'lat': float(lat),
            'lon': float(lon),
            'shift_optimo': int(best_shift),
            'correlacion_max': float(best_corr),
            'correlacion_abs_max': float(best_abs_corr),
            'puntos_validos': int(len(common_idx)),
            'correlaciones_shifts': correlaciones,
            'shifts': list(shifts)
        }
        
    except Exception as e:
        print(f"Error en nodo ({lat:.2f}, {lon:.2f}): {str(e)}")
        return {
            'lat': float(lat),
            'lon': float(lon),
            'shift_optimo': np.nan,
            'correlacion_max': np.nan,
            'correlacion_abs_max': np.nan,
            'puntos_validos': 0,
            'correlaciones_shifts': [],
            'shifts': []
        }

def graficar_correlacion_shifts(df_resultados, ciudades, ruta_graficos):
    """Grafica correlación vs shift para ciudades específicas"""
    for ciudad, coords in ciudades.items():
        df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
        
        if df_valido.empty:
            print(f"No hay datos válidos para graficar cerca de {ciudad}")
            continue
            
        df_valido['distancia'] = np.sqrt(
            (df_valido['lat']-coords['lat'])**2 + 
            (df_valido['lon']-coords['lon'])**2
        )
        
        nodo_cercano = df_valido.nsmallest(1, 'distancia').iloc[0]
        
        if not nodo_cercano.get('correlaciones_shifts'):
            print(f"No hay datos de shifts para {ciudad}")
            continue
            
        try:
            plt.figure(figsize=(10, 6))
            plt.plot(nodo_cercano['shifts'], nodo_cercano['correlaciones_shifts'], 'b-', label='Correlación')
            plt.axhline(0, color='k', linestyle='--', linewidth=0.5)
            plt.axvline(0, color='k', linestyle='--', linewidth=0.5)
            
            plt.axvline(nodo_cercano['shift_optimo'], color='r', linestyle='--', 
                       label=f'Shift óptimo: {nodo_cercano["shift_optimo"]} días')
            
            plt.xlabel('Shift (días)')
            plt.ylabel('Correlación')
            plt.title(f'Correlación NAO-Sequía vs Shift\n{ciudad} (Lat: {nodo_cercano["lat"]:.2f}, Lon: {nodo_cercano["lon"]:.2f})')
            plt.grid(True, alpha=0.3)
            plt.legend()
            
            nombre_archivo = f"correlacion_shift_sequia_{ciudad.lower().replace(' ', '_')}.png"
            ruta_completa = os.path.join(ruta_graficos, nombre_archivo)
            plt.savefig(ruta_completa, dpi=300, bbox_inches='tight')
            print(f"Gráfico de {ciudad} guardado en: {ruta_completa}")
            plt.close()
            
        except Exception as e:
            print(f"Error al graficar {ciudad}: {str(e)}")

def generar_mapa_correlacion(df_resultados, ruta_salida):
    """Genera y guarda el mapa de correlaciones con estilo divergente"""
    df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
    
    if df_valido.empty:
        print("\nNo hay datos válidos para graficar.")
        return
    
    print("\nGenerando mapa de correlaciones...")
    plt.figure(figsize=(14, 10))
    ax = plt.axes(projection=ccrs.PlateCarree())
    
    ax.add_feature(cfeature.LAND, facecolor='lightgray')
    ax.add_feature(cfeature.OCEAN, facecolor='lightblue')
    ax.add_feature(cfeature.COASTLINE)
    ax.add_feature(cfeature.BORDERS, linestyle=':')
    ax.set_extent([-11, 6, 34, 45])  
    
    corr_max = df_valido['correlacion_abs_max'].max()
    sc = ax.scatter(
        df_valido['lon'], 
        df_valido['lat'], 
        c=df_valido['correlacion_max'], 
        cmap='coolwarm', 
        vmin=-corr_max, 
        vmax=corr_max,
        s=30,
        transform=ccrs.PlateCarree()
    )
    
    cbar = plt.colorbar(sc, shrink=0.7)
    cbar.set_label('Correlación NAO-Sequía')
    
    ciudades = {
        'Madrid': {'lat': 40.5, 'lon': -3.5},
        'Barcelona': {'lat': 41.25, 'lon': 2.0},
        'Sevilla': {'lat': 37.25, 'lon': -5.75},
        'Cadiz': {'lat': 36.5, 'lon': -6.25},
        'Mallorca': {'lat': 39.5, 'lon': 3.0}
    }
    
    for ciudad, coords in ciudades.items():
        ax.plot(coords['lon'], coords['lat'], 'ko', markersize=5, transform=ccrs.PlateCarree())
        ax.text(coords['lon'] + 0.1, coords['lat'] + 0.1, ciudad, 
                transform=ccrs.PlateCarree(), fontsize=10)
    
    plt.title(f"Correlaciones NAO-Sequía (P{PERCENTIL})\n(1950-2024)")
    plt.tight_layout()
    
    plt.savefig(ruta_salida, dpi=300, bbox_inches='tight')
    print(f"Mapa guardado en: {ruta_salida}")
    plt.close()

if __name__ == "__main__":
    print("Iniciando análisis de correlación NAO-Sequía (1950-2024)")
    
    try:
        nao_series = cargar_nao(RUTA_NAO)
        
        ds_viento = cargar_datos_viento(RUTA_MODULO)
        
        sequias_daily = calcular_sequias(ds_viento)
        del ds_viento  
        lat_values = np.linspace(
            float(sequias_daily.latitude.min()),
            float(sequias_daily.latitude.max()),
            num=int((float(sequias_daily.latitude.max()) - float(sequias_daily.latitude.min())) / 0.25) + 1
        )
        lon_values = np.linspace(
            float(sequias_daily.longitude.min()),
            float(sequias_daily.longitude.max()),
            num=int((float(sequias_daily.longitude.max()) - float(sequias_daily.longitude.min())) / 0.25) + 1
        )
        
        print("\nProcesando nodos...")
        resultados = []
        total_nodos = len(lat_values) * len(lon_values)
        procesados = 0
        
        for lat in lat_values:
            for lon in lon_values:
                resultados.append(procesar_nodo(lat, lon, nao_series, sequias_daily, MAX_SHIFT))
                procesados += 1
                porcentaje = procesados / total_nodos * 100
                sys.stdout.write(f"\rProgreso: {procesados}/{total_nodos} ({porcentaje:.1f}%)")
                sys.stdout.flush()
        print()
        
        df_resultados = pd.DataFrame(resultados)
        df_resultados.to_csv(RUTA_SALIDA, index=False)
        print(f"\nResultados guardados en: {RUTA_SALIDA}")
        
        ciudades = {
            'Madrid': {'lat': 40.5, 'lon': -3.5},
            'Barcelona': {'lat': 41.25, 'lon': 2.0},
            'Sevilla': {'lat': 37.25, 'lon': -5.75},
            'Cadiz': {'lat': 36.5, 'lon': -6.25},
            'Mallorca': {'lat': 39.5, 'lon': 3.0}
        }
        
        graficar_correlacion_shifts(df_resultados, ciudades, RUTA_GRAFICOS)
        
        ruta_mapa = os.path.join(os.path.dirname(RUTA_SALIDA), "mapa_correlacion_sequia_completo.png")
        generar_mapa_correlacion(df_resultados, ruta_mapa)
        
        df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
        df_valido['abs_corr'] = df_valido['correlacion_max'].abs()
        
        if not df_valido.empty:
            print("\n=== Estadísticas de Correlaciones ===")
            print(f"Nodos con datos válidos: {len(df_valido)}/{len(df_resultados)}")
            print(f"Shift medio: {df_valido['shift_optimo'].mean():.1f} días")
            print(f"Correlación absoluta máxima: {df_valido['abs_corr'].max():.3f}")
            print(f"Correlación absoluta media: {df_valido['abs_corr'].mean():.3f}")
            
            positivas = df_valido[df_valido['correlacion_max'] > 0]
            negativas = df_valido[df_valido['correlacion_max'] < 0]
            
            print("\nCorrelaciones positivas:")
            print(f"  Cantidad: {len(positivas)} ({len(positivas)/len(df_valido)*100:.1f}%)")
            if not positivas.empty:
                print(f"  Máxima: {positivas['correlacion_max'].max():.3f}")
                print(f"  Mínima: {positivas['correlacion_max'].min():.3f}")
            
            print("\nCorrelaciones negativas:")
            print(f"  Cantidad: {len(negativas)} ({len(negativas)/len(df_valido)*100:.1f}%)")
            if not negativas.empty:
                print(f"  Máxima: {negativas['correlacion_max'].max():.3f}")
                print(f"  Mínima: {negativas['correlacion_max'].min():.3f}")
        else:
            print("\nNo se encontraron correlaciones significativas.")
        
        print("\nProceso completado exitosamente!")
    
    except Exception as e:
        print(f"\nError durante la ejecución: {str(e)}")
        raise
