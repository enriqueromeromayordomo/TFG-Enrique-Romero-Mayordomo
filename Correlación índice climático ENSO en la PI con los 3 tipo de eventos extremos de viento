import pandas as pd
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import pearsonr
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import os
from matplotlib.colors import Normalize
from datetime import datetime


RUTA_WIND = "F:/windgust/data_daily_gust_1950_2012.nc"
RUTA_ENSO = "F:/variables climaticas/ENSO/ENSO_serie_temporal_1950_2024.csv"
RUTA_SALIDA = "F:/variables climaticas/ENSO/correlacion_shift_ENSO.csv"
RUTA_MAPA = "F:/variables climaticas/ENSO/mapa_correlacion_ENSO.png"
MAX_SHIFT = 120  

def cargar_enso(ruta):
    """Carga y prepara los datos ENSO"""
    df = pd.read_csv(ruta, parse_dates=['Fecha'])
    df = df[(df['Fecha'] >= '1950-01-01') & (df['Fecha'] <= '2012-12-31')]
    return df.set_index('Fecha')['Anomalia']

def procesar_nodo(lat, lon, enso_series, ds_wind, max_shift):
    """Procesa un nodo individual, considerando correlaciones positivas y negativas"""
    try:
        nodo_wind = ds_wind["var29"].sel(
            lat=lat, lon=lon, 
            method="nearest",
            tolerance=0.125
        )
        
        fechas_wind = pd.to_datetime(
            [f"{int(t)}"[:8] for t in nodo_wind.time.values], 
            format='%Y%m%d'
        )
        
        wind_series = pd.Series(
            nodo_wind.values,
            index=fechas_wind
        ).dropna()
        
        common_dates = wind_series.index.intersection(enso_series.index)
        wind_aligned = wind_series[common_dates]
        enso_aligned = enso_series[common_dates]
        
        best_corr = 0
        best_shift = 0
        best_abs_corr = 0  
        
        for shift in range(0, max_shift + 1, 5):
            shifted_enso = enso_aligned.shift(-shift).dropna()
            wind_valid = wind_aligned[shifted_enso.index]
            
            if len(wind_valid) > 365:  
                corr = pearsonr(shifted_enso, wind_valid)[0]
                
                if abs(corr) > abs(best_abs_corr):
                    best_abs_corr = corr
                    best_corr = corr
                    best_shift = shift
        
        for shift in range(max(0, best_shift-4), min(max_shift, best_shift+5)):
            shifted_enso = enso_aligned.shift(-shift).dropna()
            wind_valid = wind_aligned[shifted_enso.index]
            
            if len(wind_valid) > 365:
                corr = pearsonr(shifted_enso, wind_valid)[0]
                if abs(corr) > abs(best_abs_corr):
                    best_abs_corr = corr
                    best_corr = corr
                    best_shift = shift
        
        return {
            'lat': lat,
            'lon': lon,
            'shift_optimo': best_shift,
            'correlacion_max': best_corr,
            'correlacion_abs_max': abs(best_corr),
            'puntos_validos': len(common_dates)
        }
        
    except Exception as e:
        print(f"Error procesando nodo ({lat}, {lon}): {str(e)}")
        return {
            'lat': lat,
            'lon': lon,
            'shift_optimo': np.nan,
            'correlacion_max': np.nan,
            'correlacion_abs_max': np.nan,
            'puntos_validos': 0
        }

def generar_mapa_correlacion(df_resultados, ruta_salida):
    """Genera y guarda el mapa de correlaciones con estilo divergente"""
    df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
    
    if df_valido.empty:
        print("\nNo hay datos válidos para graficar.")
        return
    
    print("\nGenerando mapa de correlaciones...")
    plt.figure(figsize=(14, 10))
    ax = plt.axes(projection=ccrs.PlateCarree())
    
    ax.add_feature(cfeature.LAND, facecolor='lightgray')
    ax.add_feature(cfeature.OCEAN, facecolor='lightblue')
    ax.add_feature(cfeature.COASTLINE)
    ax.add_feature(cfeature.BORDERS, linestyle=':')
    
    corr_max = df_valido['correlacion_abs_max'].max()
    sc = ax.scatter(
        df_valido['lon'], 
        df_valido['lat'], 
        c=df_valido['correlacion_max'], 
        cmap='coolwarm', 
        vmin=-corr_max, 
        vmax=corr_max,
        s=30,
        transform=ccrs.PlateCarree()
    )
    
    cbar = plt.colorbar(sc, shrink=0.7)
    cbar.set_label('Correlación ENSO-Wind Gust')
    
    max_idx = df_valido['correlacion_abs_max'].idxmax()
    max_row = df_valido.loc[max_idx]
    ax.scatter(
        max_row['lon'], max_row['lat'],
        s=100, edgecolor='black', linewidth=2,
        facecolor='none', transform=ccrs.PlateCarree(),
        label=f'Máx. correlación: {max_row["correlacion_max"]:.2f}'
    )
    
    plt.title("Correlaciones ENSO-Wind Gust (1950-2012)")
    plt.legend()
    plt.tight_layout()
    
    plt.savefig(ruta_salida, dpi=300, bbox_inches='tight')
    print(f"Mapa guardado en: {ruta_salida}")
    plt.close()

def mostrar_estadisticas_detalladas(df_resultados):
    """Muestra estadísticas detalladas de las correlaciones"""
    df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
    df_valido['abs_corr'] = df_valido['correlacion_max'].abs()
    
    if not df_valido.empty:
        max_idx = df_valido['abs_corr'].idxmax()
        max_row = df_valido.loc[max_idx]
        

        print(f"[CORRELACIÓN ABSOLUTA MÁXIMA]")
        print(f"Valor: {max_row['correlacion_max']:.3f} (abs: {max_row['abs_corr']:.3f})")
        print(f"Ubicación: ({max_row['lat']:.2f}°N, {max_row['lon']:.2f}°E)")
        print(f"Shift óptimo: {max_row['shift_optimo']} días\n")
        
        positivas = df_valido[df_valido['correlacion_max'] > 0]
        negativas = df_valido[df_valido['correlacion_max'] < 0]
        
        print("[CORRELACIONES POSITIVAS]")
        if not positivas.empty:
            max_pos = positivas['correlacion_max'].max()
            min_pos = positivas['correlacion_max'].min()
            max_pos_row = positivas[positivas['correlacion_max'] == max_pos].iloc[0]
            min_pos_row = positivas[positivas['correlacion_max'] == min_pos].iloc[0]
            
            print(f" Máxima positiva: {max_pos:.3f}")
            print(f"  Ubicación: ({max_pos_row['lat']:.2f}°N, {max_pos_row['lon']:.2f}°E)")
            print(f"  Shift óptimo: {max_pos_row['shift_optimo']} días\n")
            
            print(f" Mínima positiva: {min_pos:.3f}")
            print(f"  Ubicación: ({min_pos_row['lat']:.2f}°N, {min_pos_row['lon']:.2f}°E)")
            print(f"  Shift óptimo: {min_pos_row['shift_optimo']} días\n")
            
            print(f"Total positivas: {len(positivas)} ({len(positivas)/len(df_valido)*100:.1f}%)\n")
        else:
            print("No hay correlaciones positivas significativas\n")
        
        print("[CORRELACIONES NEGATIVAS]")
        if not negativas.empty:
            max_neg = negativas['correlacion_max'].max()  
            min_neg = negativas['correlacion_max'].min()
            max_neg_row = negativas[negativas['correlacion_max'] == max_neg].iloc[0]
            min_neg_row = negativas[negativas['correlacion_max'] == min_neg].iloc[0]
            
            print(f"► Menos negativa (cercana a 0): {max_neg:.3f}")
            print(f"  Ubicación: ({max_neg_row['lat']:.2f}°N, {max_neg_row['lon']:.2f}°E)")
            print(f"  Shift óptimo: {max_neg_row['shift_optimo']} días\n")
            
            print(f"► Más negativa: {min_neg:.3f}")
            print(f"  Ubicación: ({min_neg_row['lat']:.2f}°N, {min_neg_row['lon']:.2f}°E)")
            print(f"  Shift óptimo: {min_neg_row['shift_optimo']} días\n")
            
            print(f"Total negativas: {len(negativas)} ({len(negativas)/len(df_valido)*100:.1f}%)")
        else:
            print("No hay correlaciones negativas significativas")
    else:
        print("\nNo se encontraron correlaciones significativas.")

if __name__ == "__main__":
    print("Iniciando análisis de correlación ENSO-Wind Gust (1950-2012)")
    
    try:
        print("Cargando datos...")
        enso_series = cargar_enso(RUTA_ENSO)
        ds_wind = xr.open_dataset(RUTA_WIND, decode_times=False)
        
        lat_values = np.arange(
            round(float(ds_wind.lat.min()), 2),
            round(float(ds_wind.lat.max()), 2) + 0.25,
            0.25
        )
        lon_values = np.arange(
            round(float(ds_wind.lon.min()), 2),
            round(float(ds_wind.lon.max()), 2) + 0.25,
            0.25
        )
        
        print("\nIniciando procesamiento de todos los nodos...")
        resultados = []
        total_nodos = len(lat_values) * len(lon_values)
        nodos_procesados = 0
        
        for lat in lat_values:
            for lon in lon_values:
                nodos_procesados += 1
                print(f"\rProgreso: {nodos_procesados}/{total_nodos} nodos | Lat: {lat:.2f} Lon: {lon:.2f}", end="")
                resultados.append(procesar_nodo(lat, lon, enso_series, ds_wind, MAX_SHIFT))
        
        df_resultados = pd.DataFrame(resultados)
        df_resultados.to_csv(RUTA_SALIDA, index=False)
        print(f"\n\nResultados guardados en: {RUTA_SALIDA}")
        
        generar_mapa_correlacion(df_resultados, RUTA_MAPA)
        
        mostrar_estadisticas_detalladas(df_resultados)
        
        print("\nProceso completado exitosamente!")
    
    except Exception as e:
        print(f"\nError durante la ejecución: {str(e)}")
        raise











import pandas as pd
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import pearsonr
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import os
import glob
import warnings
import sys
from matplotlib.colors import Normalize

RUTA_MODULO = "F:/moduloydireccion/[0-9][0-9][0-9][0-9]modulo.nc"
RUTA_ENSO = "F:/variables climaticas/ENSO/ENSO_serie_temporal_1950_2024.csv"
RUTA_SALIDA = "F:/variables climaticas/ENSO/correlacion_shift_ENSO_extremo_1950_2020.csv"
RUTA_MAPA = "F:/variables climaticas/ENSO/mapa_correlacion_ENSO_extremo.png"
MAX_SHIFT = 120  
PERCENTIL = 99   
REGION_IBERICA = {'lat_min': 34, 'lat_max': 45, 'lon_min': -11, 'lon_max': 6}

def mostrar_progreso(iterable, desc=None, total=None):
    """Muestra una barra de progreso simple"""
    if total is None and hasattr(iterable, '__len__'):
        total = len(iterable)
    
    if desc:
        print(desc)
    
    for i, item in enumerate(iterable):
        yield item
        if total:
            porcentaje = (i + 1) / total * 100
            sys.stdout.write(f"\rProgreso: {i+1}/{total} ({porcentaje:.1f}%)")
            sys.stdout.flush()
    
    if total:
        print()

def cargar_enso(ruta):
    """Carga y prepara los datos ENSO"""
    print("\nCargando datos ENSO...")
    df = pd.read_csv(ruta, parse_dates=['Fecha'])
    return df[(df['Fecha'] >= '1950-01-01') & (df['Fecha'] <= '2020-12-31')].set_index('Fecha')['Anomalia']

def cargar_datos_viento(ruta_patron):
    """Carga archivos de viento de forma eficiente en memoria"""
    archivos = sorted(glob.glob(ruta_patron))
    
    if not archivos:
        raise ValueError("No se encontraron archivos que coincidan con el patrón")
    
    print("\nCargando datos de viento (1950-2020) por bloques...")
    
    template = None
    for archivo in archivos[:5]:
        try:
            with xr.open_dataset(archivo) as ds:
                time_var = next((v for v in ds.dims if v.lower() in ['time', 'valid_time', 'ftime']), None)
                wind_var = next((v for v in ds.data_vars if 'wind' in v.lower()), None)
                
                if time_var and wind_var:
                    template = ds[wind_var].isel({time_var: 0})
                    break
        except Exception as e:
            continue
    
    if template is None:
        raise ValueError("No se pudo determinar la estructura de los datos")
    
    lat_slice = slice(REGION_IBERICA['lat_max'], REGION_IBERICA['lat_min'])
    lon_slice = slice(REGION_IBERICA['lon_min'], REGION_IBERICA['lon_max'])
    
    template = template.sel(latitude=lat_slice, longitude=lon_slice)
    
    datasets = []
    for archivo in mostrar_progreso(archivos, "Procesando archivos de viento"):
        try:
            year = int(os.path.basename(archivo)[:4])
            if 1950 <= year <= 2020:
                with xr.open_dataset(archivo) as ds:
                    time_var = next((v for v in ds.dims if v.lower() in ['time', 'valid_time', 'ftime']), None)
                    wind_var = next((v for v in ds.data_vars if 'wind' in v.lower()), None)
                    
                    if time_var and wind_var:
                        if time_var != 'time':
                            ds = ds.rename({time_var: 'time'})
                        
                        ds = ds[[wind_var]].sel(latitude=lat_slice, longitude=lon_slice)
                        
                        ds[wind_var] = ds[wind_var].astype('float32')
                        
                        datasets.append(ds.load())
        except Exception as e:
            print(f"\nError procesando {os.path.basename(archivo)}: {str(e)}")
            continue
    
    if not datasets:
        raise ValueError("No se encontraron datos válidos después del procesamiento")
    
    print("\nConcatenando datos...")
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        combined = xr.concat(datasets, dim='time', combine_attrs='override', coords='minimal')
    
    return combined

def calcular_extremos_viento(ds_viento):
    """Identifica días con viento extremo según percentil 99 (valores altos de viento)"""
    print("\nCalculando días con viento extremo...")
    
    wind_var = list(ds_viento.data_vars)[0]
    
    print("Calculando máximo diario...")
    daily_max = ds_viento[wind_var].resample(time='1D').max()
    
    print(f"Calculando percentil {PERCENTIL}...")
    percentil = daily_max.quantile(PERCENTIL/100, dim='time')
    
    print("Creando máscara de extremos...")
    extremos = xr.where(daily_max >= percentil, 1, 0)
    
    return extremos

def procesar_nodo(lat, lon, enso_series, extremos_daily, max_shift):
    """Procesa un nodo individual considerando correlaciones positivas y negativas"""
    try:
        nodo_data = extremos_daily.sel(
            latitude=lat,
            longitude=lon,
            method="nearest"
        )
        
        extremos_series = pd.Series(
            nodo_data.values,
            index=pd.to_datetime(nodo_data.time.values),
            dtype='int8' 
        ).dropna()
        
        common_idx = enso_series.index.intersection(extremos_series.index)
        if len(common_idx) < 365:
            raise ValueError("Datos insuficientes")
        
        enso_aligned = enso_series[common_idx]
        extremos_aligned = extremos_series[common_idx]
        
        best_corr = 0
        best_shift = 0
        best_abs_corr = 0  
        for shift in range(0, max_shift + 1, 5):
            shifted_enso = enso_aligned.shift(-shift).dropna()
            extremos_valid = extremos_aligned[shifted_enso.index]
            
            if len(extremos_valid) > 365:
                corr = pearsonr(shifted_enso, extremos_valid)[0]
                
                if abs(corr) > abs(best_abs_corr):
                    best_abs_corr = abs(corr)
                    best_corr = corr
                    best_shift = shift
        
        for shift in range(max(0, best_shift-4), min(max_shift, best_shift+5)):
            shifted_enso = enso_aligned.shift(-shift).dropna()
            extremos_valid = extremos_aligned[shifted_enso.index]
            
            if len(extremos_valid) > 365:
                corr = pearsonr(shifted_enso, extremos_valid)[0]
                if abs(corr) > abs(best_abs_corr):
                    best_abs_corr = abs(corr)
                    best_corr = corr
                    best_shift = shift
        
        return {
            'lat': float(lat),
            'lon': float(lon),
            'shift_optimo': int(best_shift),
            'correlacion_max': float(best_corr),
            'correlacion_abs_max': float(best_abs_corr),
            'puntos_validos': int(len(common_idx))
        }
        
    except Exception as e:
        print(f"Error en nodo ({lat:.2f}, {lon:.2f}): {str(e)}")
        return {
            'lat': float(lat),
            'lon': float(lon),
            'shift_optimo': np.nan,
            'correlacion_max': np.nan,
            'correlacion_abs_max': np.nan,
            'puntos_validos': 0
        }

def generar_mapa_correlacion(df_resultados, ruta_salida):
    """Genera y guarda el mapa de correlaciones con estilo divergente"""
    df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
    
    if df_valido.empty:
        print("\nNo hay datos válidos para graficar.")
        return
    
    print("\nGenerando mapa de correlaciones...")
    plt.figure(figsize=(14, 10))
    ax = plt.axes(projection=ccrs.PlateCarree())
    
    ax.add_feature(cfeature.LAND, facecolor='lightgray')
    ax.add_feature(cfeature.OCEAN, facecolor='lightblue')
    ax.add_feature(cfeature.COASTLINE)
    ax.add_feature(cfeature.BORDERS, linestyle=':')
    ax.set_extent([-11, 6, 34, 45])  
    
    corr_max = df_valido['correlacion_abs_max'].max()
    sc = ax.scatter(
        df_valido['lon'], 
        df_valido['lat'], 
        c=df_valido['correlacion_max'], 
        cmap='coolwarm', 
        vmin=-corr_max, 
        vmax=corr_max,
        s=30,
        transform=ccrs.PlateCarree()
    )
    
    cbar = plt.colorbar(sc, shrink=0.7)
    cbar.set_label('Correlación ENSO-Viento Extremo')
    
    max_idx = df_valido['correlacion_abs_max'].idxmax()
    max_row = df_valido.loc[max_idx]
    ax.scatter(
        max_row['lon'], max_row['lat'],
        s=100, edgecolor='black', linewidth=2,
        facecolor='none', transform=ccrs.PlateCarree(),
        label=f'Máx. correlación: {max_row["correlacion_max"]:.2f}'
    )
    
    ciudades = {
        'Madrid': {'lat': 40.5, 'lon': -3.5},
        'Barcelona': {'lat': 41.25, 'lon': 2.0},
        'Sevilla': {'lat': 37.25, 'lon': -5.75},
        'Cadiz': {'lat': 36.5, 'lon': -6.25},
        'Mallorca': {'lat': 39.5, 'lon': 3.0}
    }
    
    for ciudad, coords in ciudades.items():
        ax.plot(coords['lon'], coords['lat'], 'ko', markersize=5, transform=ccrs.PlateCarree())
        ax.text(coords['lon'] + 0.1, coords['lat'] + 0.1, ciudad, 
                transform=ccrs.PlateCarree(), fontsize=10)
    
    plt.title(f"Correlaciones ENSO-Viento Extremo (P{PERCENTIL})\n(1950-2020)")
    plt.legend()
    plt.tight_layout()
    
    plt.savefig(ruta_salida, dpi=300, bbox_inches='tight')
    print(f"Mapa guardado en: {ruta_salida}")
    plt.close()

def mostrar_estadisticas_detalladas(df_resultados):
    """Muestra estadísticas detalladas de las correlaciones"""
    df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
    df_valido['abs_corr'] = df_valido['correlacion_max'].abs()
    
    if not df_valido.empty:
        max_idx = df_valido['abs_corr'].idxmax()
        max_row = df_valido.loc[max_idx]
        
        print("\n=== ESTADÍSTICAS DETALLADAS ===")
        print(f"[CORRELACIÓN ABSOLUTA MÁXIMA]")
        print(f"Valor: {max_row['correlacion_max']:.3f} (abs: {max_row['abs_corr']:.3f})")
        print(f"Ubicación: ({max_row['lat']:.2f}°N, {max_row['lon']:.2f}°E)")
        print(f"Shift óptimo: {max_row['shift_optimo']} días\n")
        
        positivas = df_valido[df_valido['correlacion_max'] > 0]
        negativas = df_valido[df_valido['correlacion_max'] < 0]
        
        print("[CORRELACIONES POSITIVAS]")
        if not positivas.empty:
            max_pos = positivas['correlacion_max'].max()
            min_pos = positivas['correlacion_max'].min()
            max_pos_row = positivas[positivas['correlacion_max'] == max_pos].iloc[0]
            min_pos_row = positivas[positivas['correlacion_max'] == min_pos].iloc[0]
            
            print(f"► Máxima positiva: {max_pos:.3f}")
            print(f"  Ubicación: ({max_pos_row['lat']:.2f}°N, {max_pos_row['lon']:.2f}°E)")
            print(f"  Shift óptimo: {max_pos_row['shift_optimo']} días\n")
            
            print(f"► Mínima positiva: {min_pos:.3f}")
            print(f"  Ubicación: ({min_pos_row['lat']:.2f}°N, {min_pos_row['lon']:.2f}°E)")
            print(f"  Shift óptimo: {min_pos_row['shift_optimo']} días\n")
            
            print(f"Total positivas: {len(positivas)} ({len(positivas)/len(df_valido)*100:.1f}%)\n")
        else:
            print("No hay correlaciones positivas significativas\n")
        
        print("[CORRELACIONES NEGATIVAS]")
        if not negativas.empty:
            max_neg = negativas['correlacion_max'].max()  
            min_neg = negativas['correlacion_max'].min() 
            max_neg_row = negativas[negativas['correlacion_max'] == max_neg].iloc[0]
            min_neg_row = negativas[negativas['correlacion_max'] == min_neg].iloc[0]
            
            print(f"► Menos negativa (cercana a 0): {max_neg:.3f}")
            print(f"  Ubicación: ({max_neg_row['lat']:.2f}°N, {max_neg_row['lon']:.2f}°E)")
            print(f"  Shift óptimo: {max_neg_row['shift_optimo']} días\n")
            
            print(f"► Más negativa: {min_neg:.3f}")
            print(f"  Ubicación: ({min_neg_row['lat']:.2f}°N, {min_neg_row['lon']:.2f}°E)")
            print(f"  Shift óptimo: {min_neg_row['shift_optimo']} días\n")
            
            print(f"Total negativas: {len(negativas)} ({len(negativas)/len(df_valido)*100:.1f}%)")
        else:
            print("No hay correlaciones negativas significativas")
    else:
        print("\nNo se encontraron correlaciones significativas.")

if __name__ == "__main__":
    print("Iniciando análisis de correlación ENSO-Viento Extremo (1950-2020)")
    
    try:
        enso_series = cargar_enso(RUTA_ENSO)
        
        ds_viento = cargar_datos_viento(RUTA_MODULO)
        
        extremos_daily = calcular_extremos_viento(ds_viento)
        del ds_viento  
        lat_values = np.linspace(
            float(extremos_daily.latitude.min()),
            float(extremos_daily.latitude.max()),
            num=int((float(extremos_daily.latitude.max()) - float(extremos_daily.latitude.min())) / 0.25) + 1
        )
        lon_values = np.linspace(
            float(extremos_daily.longitude.min()),
            float(extremos_daily.longitude.max()),
            num=int((float(extremos_daily.longitude.max()) - float(extremos_daily.longitude.min())) / 0.25) + 1
        )
        
        print("\nProcesando nodos...")
        resultados = []
        total_nodos = len(lat_values) * len(lon_values)
        procesados = 0
        
        for lat in lat_values:
            for lon in lon_values:
                resultados.append(procesar_nodo(lat, lon, enso_series, extremos_daily, MAX_SHIFT))
                procesados += 1
                porcentaje = procesados / total_nodos * 100
                sys.stdout.write(f"\rProgreso: {procesados}/{total_nodos} ({porcentaje:.1f}%)")
                sys.stdout.flush()
        print()
        
        df_resultados = pd.DataFrame(resultados)
        df_resultados.to_csv(RUTA_SALIDA, index=False)
        print(f"\nResultados guardados en: {RUTA_SALIDA}")
        
        generar_mapa_correlacion(df_resultados, RUTA_MAPA)
        
        mostrar_estadisticas_detalladas(df_resultados)
        
        print("\nProceso completado exitosamente!")
    
    except Exception as e:
        print(f"\nError durante la ejecución: {str(e)}")
        raise















import pandas as pd
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import pearsonr
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import os
import glob
import warnings
import sys
from matplotlib.colors import Normalize

RUTA_MODULO = "F:/moduloydireccion/[0-9][0-9][0-9][0-9]modulo.nc"
RUTA_ENSO = "F:/variables climaticas/ENSO/ENSO_serie_temporal_1950_2024.csv"
RUTA_SALIDA = "F:/variables climaticas/ENSO/correlacion_shift_ENSO_sequia_1950_2020.csv"
RUTA_MAPA = "F:/variables climaticas/ENSO/mapa_correlacion_ENSO_sequia.png"
MAX_SHIFT = 120 
PERCENTIL = 20  
REGION_IBERICA = {'lat_min': 34, 'lat_max': 45, 'lon_min': -11, 'lon_max': 6}

def mostrar_progreso(iterable, desc=None, total=None):
    """Muestra una barra de progreso simple"""
    if total is None and hasattr(iterable, '__len__'):
        total = len(iterable)
    
    if desc:
        print(desc)
    
    for i, item in enumerate(iterable):
        yield item
        if total:
            porcentaje = (i + 1) / total * 100
            sys.stdout.write(f"\rProgreso: {i+1}/{total} ({porcentaje:.1f}%)")
            sys.stdout.flush()
    
    if total:
        print()

def cargar_enso(ruta):
    """Carga y prepara los datos ENSO"""
    print("\nCargando datos ENSO...")
    df = pd.read_csv(ruta, parse_dates=['Fecha'])
  
    return df[(df['Fecha'] >= '1950-01-01') & (df['Fecha'] <= '2020-12-31')].set_index('Fecha')['Anomalia']

def cargar_datos_viento(ruta_patron):
    """Carga archivos de viento de forma eficiente en memoria"""
    archivos = sorted(glob.glob(ruta_patron))
    
    if not archivos:
        raise ValueError("No se encontraron archivos que coincidan con el patrón")
    
    print("\nCargando datos de viento (1950-2020) por bloques...")
    
    template = None
    for archivo in archivos[:5]:
        try:
            with xr.open_dataset(archivo) as ds:
                time_var = next((v for v in ds.dims if v.lower() in ['time', 'valid_time', 'ftime']), None)
                wind_var = next((v for v in ds.data_vars if 'wind' in v.lower()), None)
                
                if time_var and wind_var:
                    template = ds[wind_var].isel({time_var: 0})
                    break
        except Exception as e:
            continue
    
    if template is None:
        raise ValueError("No se pudo determinar la estructura de los datos")
    
    lat_slice = slice(REGION_IBERICA['lat_max'], REGION_IBERICA['lat_min'])
    lon_slice = slice(REGION_IBERICA['lon_min'], REGION_IBERICA['lon_max'])
    
    template = template.sel(latitude=lat_slice, longitude=lon_slice)
    
    datasets = []
    for archivo in mostrar_progreso(archivos, "Procesando archivos de viento"):
        try:
            year = int(os.path.basename(archivo)[:4])
            if 1950 <= year <= 2020:
                with xr.open_dataset(archivo) as ds:
                    time_var = next((v for v in ds.dims if v.lower() in ['time', 'valid_time', 'ftime']), None)
                    wind_var = next((v for v in ds.data_vars if 'wind' in v.lower()), None)
                    
                    if time_var and wind_var:
                        if time_var != 'time':
                            ds = ds.rename({time_var: 'time'})
                        
                        ds = ds[[wind_var]].sel(latitude=lat_slice, longitude=lon_slice)
                        
                        ds[wind_var] = ds[wind_var].astype('float32')
                        
                        datasets.append(ds.load())
        except Exception as e:
            print(f"\nError procesando {os.path.basename(archivo)}: {str(e)}")
            continue
    
    if not datasets:
        raise ValueError("No se encontraron datos válidos después del procesamiento")
    
    print("\nConcatenando datos...")
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        combined = xr.concat(datasets, dim='time', combine_attrs='override', coords='minimal')
    
    return combined

def calcular_sequias(ds_viento):
    """Identifica días de sequía según percentil 20 (valores bajos de viento)"""
    print("\nCalculando días de sequía...")
    
    wind_var = list(ds_viento.data_vars)[0]
    
    print("Calculando mínimo diario...")
    daily_min = ds_viento[wind_var].resample(time='1D').min()
    
    print("Calculando percentil 20...")
    percentil = daily_min.quantile(PERCENTIL/100, dim='time')
    
    print("Creando máscara de sequía...")
    sequias = xr.where(daily_min <= percentil, 1, 0)
    
    return sequias

def procesar_nodo(lat, lon, enso_series, sequias_daily, max_shift):
    """Procesa un nodo individual considerando correlaciones positivas y negativas"""
    try:
        nodo_data = sequias_daily.sel(
            latitude=lat,
            longitude=lon,
            method="nearest"
        )
        
        sequia_series = pd.Series(
            nodo_data.values,
            index=pd.to_datetime(nodo_data.time.values),
            dtype='int8'  
        ).dropna()
        
        common_idx = enso_series.index.intersection(sequia_series.index)
        if len(common_idx) < 365:
            raise ValueError("Datos insuficientes")
        
        enso_aligned = enso_series[common_idx]
        sequia_aligned = sequia_series[common_idx]
        
        best_corr = 0
        best_shift = 0
        best_abs_corr = 0  
        for shift in range(0, max_shift + 1, 5):
            shifted_enso = enso_aligned.shift(-shift).dropna()
            sequia_valid = sequia_aligned[shifted_enso.index]
            
            if len(sequia_valid) > 365:
                corr = pearsonr(shifted_enso, sequia_valid)[0]
                
                if abs(corr) > abs(best_abs_corr):
                    best_abs_corr = abs(corr)
                    best_corr = corr
                    best_shift = shift
        
        for shift in range(max(0, best_shift-4), min(max_shift, best_shift+5)):
            shifted_enso = enso_aligned.shift(-shift).dropna()
            sequia_valid = sequia_aligned[shifted_enso.index]
            
            if len(sequia_valid) > 365:
                corr = pearsonr(shifted_enso, sequia_valid)[0]
                if abs(corr) > abs(best_abs_corr):
                    best_abs_corr = abs(corr)
                    best_corr = corr
                    best_shift = shift
        
        return {
            'lat': float(lat),
            'lon': float(lon),
            'shift_optimo': int(best_shift),
            'correlacion_max': float(best_corr),
            'correlacion_abs_max': float(best_abs_corr),
            'puntos_validos': int(len(common_idx))
        }
        
    except Exception as e:
        print(f"Error en nodo ({lat:.2f}, {lon:.2f}): {str(e)}")
        return {
            'lat': float(lat),
            'lon': float(lon),
            'shift_optimo': np.nan,
            'correlacion_max': np.nan,
            'correlacion_abs_max': np.nan,
            'puntos_validos': 0
        }

def generar_mapa_correlacion(df_resultados, ruta_salida):
    """Genera y guarda el mapa de correlaciones con estilo divergente"""
    df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
    
    if df_valido.empty:
        print("\nNo hay datos válidos para graficar.")
        return
    
    print("\nGenerando mapa de correlaciones...")
    plt.figure(figsize=(14, 10))
    ax = plt.axes(projection=ccrs.PlateCarree())
    
    ax.add_feature(cfeature.LAND, facecolor='lightgray')
    ax.add_feature(cfeature.OCEAN, facecolor='lightblue')
    ax.add_feature(cfeature.COASTLINE)
    ax.add_feature(cfeature.BORDERS, linestyle=':')
    ax.set_extent([-11, 6, 34, 45]) 
    
    corr_max = df_valido['correlacion_abs_max'].max()
    sc = ax.scatter(
        df_valido['lon'], 
        df_valido['lat'], 
        c=df_valido['correlacion_max'], 
        cmap='coolwarm', 
        vmin=-corr_max, 
        vmax=corr_max,
        s=30,
        transform=ccrs.PlateCarree()
    )
    
    cbar = plt.colorbar(sc, shrink=0.7)
    cbar.set_label('Correlación ENSO-Sequía')
    
    max_idx = df_valido['correlacion_abs_max'].idxmax()
    max_row = df_valido.loc[max_idx]
    ax.scatter(
        max_row['lon'], max_row['lat'],
        s=100, edgecolor='black', linewidth=2,
        facecolor='none', transform=ccrs.PlateCarree(),
        label=f'Máx. correlación: {max_row["correlacion_max"]:.2f}'
    )
    
    ciudades = {
        'Madrid': {'lat': 40.5, 'lon': -3.5},
        'Barcelona': {'lat': 41.25, 'lon': 2.0},
        'Sevilla': {'lat': 37.25, 'lon': -5.75},
        'Cadiz': {'lat': 36.5, 'lon': -6.25},
        'Mallorca': {'lat': 39.5, 'lon': 3.0}
    }
    
    for ciudad, coords in ciudades.items():
        ax.plot(coords['lon'], coords['lat'], 'ko', markersize=5, transform=ccrs.PlateCarree())
        ax.text(coords['lon'] + 0.1, coords['lat'] + 0.1, ciudad, 
                transform=ccrs.PlateCarree(), fontsize=10)
    
    plt.title(f"Correlaciones ENSO-Sequía (P{PERCENTIL})\n(1950-2020)")
    plt.legend()
    plt.tight_layout()
    
    plt.savefig(ruta_salida, dpi=300, bbox_inches='tight')
    print(f"Mapa guardado en: {ruta_salida}")
    plt.close()

def mostrar_estadisticas_detalladas(df_resultados):
    """Muestra estadísticas detalladas de las correlaciones"""
    df_valido = df_resultados[df_resultados['puntos_validos'] > 0].copy()
    df_valido['abs_corr'] = df_valido['correlacion_max'].abs()
    
    if not df_valido.empty:
        max_idx = df_valido['abs_corr'].idxmax()
        max_row = df_valido.loc[max_idx]
        
        print("\n=== ESTADÍSTICAS DETALLADAS ===")
        print(f"[CORRELACIÓN ABSOLUTA MÁXIMA]")
        print(f"Valor: {max_row['correlacion_max']:.3f} (abs: {max_row['abs_corr']:.3f})")
        print(f"Ubicación: ({max_row['lat']:.2f}°N, {max_row['lon']:.2f}°E)")
        print(f"Shift óptimo: {max_row['shift_optimo']} días\n")
        
        positivas = df_valido[df_valido['correlacion_max'] > 0]
        negativas = df_valido[df_valido['correlacion_max'] < 0]
        
        print("[CORRELACIONES POSITIVAS]")
        if not positivas.empty:
            max_pos = positivas['correlacion_max'].max()
            min_pos = positivas['correlacion_max'].min()
            max_pos_row = positivas[positivas['correlacion_max'] == max_pos].iloc[0]
            min_pos_row = positivas[positivas['correlacion_max'] == min_pos].iloc[0]
            
            print(f"► Máxima positiva: {max_pos:.3f}")
            print(f"  Ubicación: ({max_pos_row['lat']:.2f}°N, {max_pos_row['lon']:.2f}°E)")
            print(f"  Shift óptimo: {max_pos_row['shift_optimo']} días\n")
            
            print(f"► Mínima positiva: {min_pos:.3f}")
            print(f"  Ubicación: ({min_pos_row['lat']:.2f}°N, {min_pos_row['lon']:.2f}°E)")
            print(f"  Shift óptimo: {min_pos_row['shift_optimo']} días\n")
            
            print(f"Total positivas: {len(positivas)} ({len(positivas)/len(df_valido)*100:.1f}%)\n")
        else:
            print("No hay correlaciones positivas significativas\n")
        
        print("[CORRELACIONES NEGATIVAS]")
        if not negativas.empty:
            max_neg = negativas['correlacion_max'].max() 
            min_neg = negativas['correlacion_max'].min() 
            max_neg_row = negativas[negativas['correlacion_max'] == max_neg].iloc[0]
            min_neg_row = negativas[negativas['correlacion_max'] == min_neg].iloc[0]
            
            print(f"► Menos negativa (cercana a 0): {max_neg:.3f}")
            print(f"  Ubicación: ({max_neg_row['lat']:.2f}°N, {max_neg_row['lon']:.2f}°E)")
            print(f"  Shift óptimo: {max_neg_row['shift_optimo']} días\n")
            
            print(f"► Más negativa: {min_neg:.3f}")
            print(f"  Ubicación: ({min_neg_row['lat']:.2f}°N, {min_neg_row['lon']:.2f}°E)")
            print(f"  Shift óptimo: {min_neg_row['shift_optimo']} días\n")
            
            print(f"Total negativas: {len(negativas)} ({len(negativas)/len(df_valido)*100:.1f}%)")
        else:
            print("No hay correlaciones negativas significativas")
    else:
        print("\nNo se encontraron correlaciones significativas.")

if __name__ == "__main__":
    print("Iniciando análisis de correlación ENSO-Sequía (1950-2020)")
    
    try:
        enso_series = cargar_enso(RUTA_ENSO)
        
        ds_viento = cargar_datos_viento(RUTA_MODULO)
        
        sequias_daily = calcular_sequias(ds_viento)
        del ds_viento  
        
        lat_values = np.linspace(
            float(sequias_daily.latitude.min()),
            float(sequias_daily.latitude.max()),
            num=int((float(sequias_daily.latitude.max()) - float(sequias_daily.latitude.min())) / 0.25) + 1
        )
        lon_values = np.linspace(
            float(sequias_daily.longitude.min()),
            float(sequias_daily.longitude.max()),
            num=int((float(sequias_daily.longitude.max()) - float(sequias_daily.longitude.min())) / 0.25) + 1
        )
        
        print("\nProcesando nodos...")
        resultados = []
        total_nodos = len(lat_values) * len(lon_values)
        procesados = 0
        
        for lat in lat_values:
            for lon in lon_values:
                resultados.append(procesar_nodo(lat, lon, enso_series, sequias_daily, MAX_SHIFT))
                procesados += 1
                porcentaje = procesados / total_nodos * 100
                sys.stdout.write(f"\rProgreso: {procesados}/{total_nodos} ({porcentaje:.1f}%)")
                sys.stdout.flush()
        print()
        
        df_resultados = pd.DataFrame(resultados)
        df_resultados.to_csv(RUTA_SALIDA, index=False)
        print(f"\nResultados guardados en: {RUTA_SALIDA}")
        
        generar_mapa_correlacion(df_resultados, RUTA_MAPA)
        
        mostrar_estadisticas_detalladas(df_resultados)
        
        print("\nProceso completado exitosamente!")
    
    except Exception as e:
        print(f"\nError durante la ejecución: {str(e)}")
        raise 
